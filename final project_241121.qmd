------------------------------------------------------------------------

---
title: "SDOH of persons with dementia"
subtitle: "BMIN503/EPID600 Final Project"
author: "Hannah Cho"
format: html
editor: visual
number-sections: true
embed-resources: true
---

# *Overview*

*This project aims to investigate which demographic, caregiving social strains, and health-related factors are most predictive of high levels of emotional problems such as anxiety and depression among dementia caregivers. Using data from the National Health and Aging Trends Study (NHATS), I am applying supervised machine learning methods to analyze patterns in social support access among this population. To deepen my approach, I consulted with Drs. Demiris and Huang from the School of Nursing, who provided insights into social determinants of health and their influence on caregiving dynamics, emphasizing the role of socioeconomic factors. You can find my project repository [here](https://github.com/hacho426/BMIN503_Final_Project/blob/master/final_project_241105.qmd).*

# *Introduction*

*The challenges faced by dementia caregivers are deeply complex and multifaceted, encompassing not only the physical and emotional demands of caregiving but also social physical, and systemic barriers. These challenges are not apply physically demanding- such as providing around-the-clock care, assisting with activities of daily living, and managing the various health complications of dementia- but they also take a significant burden on the caregivers' emotional well-being. Caregivers often experience stress, anxiety, depression, and a sense of isolation, as the demands of caregiving can leave little room for self-care, personal, or social engagement. Among them, caregivers for persons with dementia are put at high risks of anxiety and depression due to the nature of the diseases. The trajectory of dementia is not quietly common and varied based on individuals' pre-exisitng problems and multicomorbidities. In addition to this uncertaintity, caregivers often face sigificant social and systemic barriers that limit their access to essential support services. These barriers include financial strain, a lack of accessible respite care, insufficient knowledge about available resources, and cultural or social stigma associated with caregiving. Many caregivers also experience isolation due to lack of social engagement.*

*\@ Research Question: Which social strains and sociodemographic characteristics of caregivers most strongly predict anxiety and depression for caregiver of persons with living dementia, and how accurately can supervised machine learning models predict these outcomes?*

# *Methods* {#sec-methods}

*Describe the data used and general methodological approach used to address the problem described in the @sec-introduction. Subsequently, incorporate full R code necessary to retrieve and clean data, and perform analysis. Be sure to include a description of code so that others (including your future self) can understand what you are doing and why.*

*\*Dataset*

*This study uses data from the National Health and Aging Trends Study (NHATS) Round 11 and the National Study of Caregiving (NSOC) Round 4, which include data collected in 2021. The NHATS is a publicly accessible dataset that includes a nationally representatative sample of adults aged 65 years old and older who are Medicare beneficiaries in the United States of America. The NSOC is conducted alongside the NHATS; participants in the NSOC are caregivers for older adults included in the NHATS. Both the NHATS and the NSOC were funded by the National Institute on Aging (R01AG062477; U01AG032947). When used together, the NHATS and NSOC provide valuable information on dyads of older adults receiving care and their family caregivers.^12^*

*\*Samples*

1.  *Probable dementia was identified based on one of the following criteria: a self-reported diagnosis of dementia or Alzheimer’s disease by a physician, a score of 2 or higher on the AD8 screening instrument administered to proxy respondents, or a score that is 1.5 standard deviations below the mean on a range of cognitive tests.*

2.  *Caregivers of probable or diagnosed dementia patients were identified from the NSOC and NHATS data set.*

    ```{r}
    #Afer retriving NHATS Round 11 and NSOC ROUND 4, I specifically selected the sample (from NHATS R11- r11demclas). And then, I merged those necessary datasets. 
    merged_data1 <- left_join(r11demclas, NHATS_Round_11_SP_File_V2, by = "spid")
    merged_data2 <- left_join(merged_data1, NSOC_cross, by = "spid")
    merged_data3 <- left_join(merged_data2, NSOC_r11,  by = "spid")

    #Since this project specifically aims to explore caregivers of persons with dementia in the community, the sample was further filtered through dementia classification (demclass) and residency (r11dresid).

    merged_dementia1 <- merged_data3 |>
      filter(demclas %in% c("1", "2") & (r11dresid  %in% c("1")))

    ```

*\*Predictors:*

```{r}
#Caregiver level factors are identified as caregivers' age, race, gender, self-reported income, and the highest education level. Also, these are recoded accordingly.  The education level of the caregivers was categorized as "Less than high school (0)”, “High School (1)”, and “College or above (2).” For economic status, the caregivers' reported income from the previous year was used. This study included both informal and formal support as part of the caregivers' social determinants of health. Informal support included having friends or family (a) to talk to about important life matters, (b) to help with daily activities, such as running errands, and (c) to assist with care provision.10 Formal support included (a) participation in a support group for caregivers, (b) access to respite services that allowed the caregiver to take time off, and (c) involvement in a training program that assisted the caregiver in providing care for the care recipient.10 We used these individual items as support questions and each support question was answered by indicating whether or not they received support.

# Age
merged_dementia1$chd11dage 
#Race
table(merged_dementia1$crl11dcgracehisp)
table(merged_dementia1$crl11dcgracehisp_recode)
# Recode `race` to create a new binary variable
# 1 for "White, non-Hispanic" and 0 for "Non-White"
merged_dementia1 <- merged_dementia1 %>%
  mutate(
    crl11dcgracehisp_recode = case_when(
      crl11dcgracehisp == 1 ~ 1,  # White, non-Hispanic
      crl11dcgracehisp %in% c(2, 3, 4, 5, 6) ~ 0  
    ))  
# Gender: Male as reference (0), Female as 1
merged_dementia1 <- merged_dementia1 |>
  mutate(c11gender_recode = case_when(
    as.character(c11gender) == "1" ~ 0,
    as.character(c11gender) == "2" ~ 1,
    TRUE ~ NA_real_  
  ))

#Education
table(merged_dementia1$chd11educ)
merged_dementia1 <- merged_dementia1|>
  mutate(chd11educ_recode = case_when(
    chd11educ %in% 1:3 ~ 1,     # Below and high school diploma (1-3) → 1
    chd11educ %in% 5:8 ~ 2,     # Some college (5-8) → 2
    chd11educ == -8 ~ NA_real_, 
    chd11educ == -7 ~ NA_real_, 
    TRUE ~ NA_real_             
  ))

merged_dementia1 <- merged_dementia1[!merged_dementia1$chi11income %in% c(-8, -6, -7, 0), ]
table(merged_dementia1$chi11income)


## marital status 
table(merged_dementia1$chd11martstat )

merged_dementia1 <- merged_dementia1|>
  mutate(chd11martstat_recode = case_when(
    chd11martstat == 1 ~ 1,     # married
    chd11martstat %in% 2:6 ~ 0,     # not married (single, divorced)
    chd11martstat == -1 ~ NA_real_, 
    TRUE ~ NA_real_             
  ))

table(merged_dementia1$chd11martstat_recode)



```

```{r}

### caregiving  
##Caregivers' Social Strains - binary questions (Y/N). In the last month, did helping the recipient ever keep you from: 1) visiting in person with friends or family not living with you? 2) participating in club meetings or group activities? 3) going out for enjoyment? 4) working for pay? 5) doing volunteer work? 6) providing care for a child or other adult?  

# Check if 'pa11hlkepfvst' exists, then create 'pa11hlkepfvst_recode'
if("pa11hlkepfvst" %in% colnames(merged_dementia1)) {
  merged_dementia1 <- merged_dementia1 %>%
    mutate(pa11hlkepfvst_recode = case_when(
      pa11hlkepfvst == 1 ~ 1,
      pa11hlkepfvst == 2 ~ 0,
      pa11hlkepfvst == -8 ~ NA_real_,  # Use NA_real_ to indicate missing values
      TRUE ~ NA_real_  # This will handle all other values as NA
    ))
} else {
  stop("Column 'pa11hlkepfvst' does not exist in the dataset.")
}
# Recode for pa11hlkpfrclb
if("pa11hlkpfrclb" %in% colnames(merged_dementia1)) {
  merged_dementia1 <- merged_dementia1 %>%
    mutate(pa11hlkpfrclb_recode = case_when(
      pa11hlkpfrclb == 1 ~ 1,  # Example recoding, modify as needed
      pa11hlkpfrclb == 2 ~ 0,  
      pa11hlkpfrclb == -8 ~ NA_real_,  # NA for missing values
      TRUE ~ NA_real_  # Handle other values as NA
    ))
} else {
  stop("Column 'pa11hlkpfrclb' does not exist in the dataset.")
}
# Recode for pa11hlkpgoenj
if("pa11hlkpgoenj" %in% colnames(merged_dementia1)) {
  merged_dementia1 <- merged_dementia1 %>%
    mutate(pa11hlkpgoenj_recode = case_when(
      pa11hlkpgoenj == 1 ~ 1,  
      pa11hlkpgoenj == 2 ~ 0,  
      pa11hlkpgoenj == -8 ~ NA_real_,  
      TRUE ~ NA_real_
    ))
} else {
  stop("Column 'pa11hlkpgoenj' does not exist in the dataset.")
}

# Recode for pa11hlkpfrwrk
if("pa11hlkpfrwrk" %in% colnames(merged_dementia1)) {
  merged_dementia1 <- merged_dementia1 %>%
    mutate(pa11hlkpfrwrk_recode = case_when(
      pa11hlkpfrwrk == 1 ~ 1,  
      pa11hlkpfrwrk == 2 ~ 0,  
      pa11hlkpfrwrk == -8 ~ NA_real_,  
      TRUE ~ NA_real_
    ))
} else {
  stop("Column 'pa11hlkpfrwrk' does not exist in the dataset.")
}
# Recode for pa11hlkpfrvol
if("pa11hlkpfrvol" %in% colnames(merged_dementia1)) {
  merged_dementia1 <- merged_dementia1 %>%
    mutate(pa11hlkpfrvol_recode = case_when(
      pa11hlkpfrvol == 1 ~ 1,  
      pa11hlkpfrvol == 2 ~ 0,  
      pa11hlkpfrvol == -8 ~ NA_real_,  
      TRUE ~ NA_real_
    ))
} else {
  stop("Column 'pa11hlkpfrvol' does not exist in the dataset.")
}
# Recode for pa11prcranoth
if("pa11prcranoth" %in% colnames(merged_dementia1)) {
  merged_dementia1 <- merged_dementia1 %>%
    mutate(pa11prcranoth_recode = case_when(
      pa11prcranoth == 1 ~ 1,  
      pa11prcranoth == 2 ~ 0,  
      pa11prcranoth %in% c(-8, -1) ~ NA_real_,  # Corrected condition
      TRUE ~ NA_real_
    ))
} else {
  stop("Column 'pa11prcranoth' does not exist in the dataset.")
}

 merged_dementia1$total_SS <- merged_dementia1$pa11prcranoth_recode + merged_dementia1$pa11hlkpfrvol_recode + merged_dementia1$pa11hlkpfrwrk_recode + merged_dementia1$pa11hlkpgoenj_recode + merged_dementia1$pa11hlkpfrclb_recode +  merged_dementia1$pa11hlkepfvst_recode + merged_dementia1$pa11hlkpfrclb_recode

 ## To quantify the total_ss_cat variable, a cutoff point of 4 was established. Values below 4 were coded as '0', indicating the absence of social strain, while values of 4 and above were considered to reflect the presence of social strain.
 merged_dementia1$total_SS_cat <- ifelse(merged_dementia1$total_SS < 4, 0, 1)

```

*#Outcome*

```{r}
#Caregivers' anxiety and depressive symptoms are measured by two questions each.First, anxiety was measured Generalized Anxiety Disorder-2 (GAD-2) Scale which consists of two questions. Since the NHATS provided GAD-2 data, this study utilized it to measure anxiety levels among care recipients. Each item on the scale is rated on a four-point Likert scale, ranging from 0 (not at all) to 3 (nearly every day), resulting in a total score between 0 and 6. Higher scores correspond to greater anxiety, with a total GAD-2 score of 3 or more indicating anxiety. The care recipients' depression was evaluated using the Patient Health Questionnaire-2 (PHQ-2) Scale.17 Given that the NHATS included PHQ-2, this study utilized it to measure depression in care recipients. Each item on the scale was measured with a four-point Likert scale, ranging from 0 (not at all) to 3 (nearly every day), resulting a total score between 0 and 6, with higher scores indicating more severe depression. Depression was defined as a total score of 3 or higher.

 # Sum the two questions for GAD2
 merged_dementia1$total_gad2 <- merged_dementia1$che11fltnervs + merged_dementia1$che11fltworry
 
 # Recode the combined variable using a cut-off of 4
 merged_dementia1$gad2_cg_cat <- ifelse(merged_dementia1$total_gad2 < 4, 0, 1)
 
# Sum of the two questions for PHQ2 (che11fltltlin + che11fltdown) 
 merged_dementia1$total_phq2 <- merged_dementia1$che11fltltlin+ merged_dementia1$che11fltdown
 merged_dementia1$phq2_cg_cat <- ifelse(merged_dementia1$total_phq2 < 4, 0, 1)
 table(merged_dementia1$phq2_cg_cat)
 summary(merged_dementia1$phq2_cg_cat)
 
```

***Data analysis***

*For data analysis, descriptive data analysis such as mean, standard deviations, ranges, and percentages were used. To examine how caregivers' social strains and caregiver level factors influence depression of caregiver, logistic regression analyses were used. Using the conceptual framework of this study as guidance, we conducted a univariate logistic regression analysis to examine which caregivers' social strains and caregiver level factors influence caregiver anxiety and depression, after controlling for care recipient-level factors. Variables with a p-value below 0.05 in the univariate analyses were incorporated into the subsequent multivariate model. Next, we built a multivariate logistic regression model to examine which caregivers' social strains and caregiver level factors influence caregiver anxiety and depression the most. All statistical analyses were conducted using R, and statistical significance was set at p-value less than 0.05.*


```{r}
#univariate logistics
lm_model_univ1 <- glm(phq2_cg_cat ~ total_SS_cat, data = merged_dementia2_sub)
lm_model_univ2 <- glm(gad2_cg_cat ~ total_SS_cat, data = merged_dementia2_sub)
summary(lm_model_univ1)
summary(lm_model_univ2)
lm_model_univ3 <- glm(phq2_cg_cat ~ pa11hlkepfvst_recode, data = merged_dementia2_sub)
summary(lm_model_univ3)
lm_model_univ4 <- glm(phq2_cg_cat ~pa11hlkpfrclb_recode, data = merged_dementia2_sub)
summary(lm_model_univ4)
lm_model_univ5 <- glm(phq2_cg_cat ~pa11hlkpgoenj_recode, data = merged_dementia2_sub)
summary(lm_model_univ5)
lm_model_univ3a <- glm(gad2_cg_cat ~ pa11hlkepfvst_recode, data = merged_dementia2_sub)
summary(lm_model_univ3a)
lm_model_univ4a <- glm(gad2_cg_cat ~pa11hlkpfrclb_recode, data = merged_dementia2_sub)
summary(lm_model_univ4a) ## significant
lm_model_univ5a <- glm(gad2_cg_cat ~pa11hlkpgoenj_recode, data = merged_dementia2_sub)
summary(lm_model_univ5a)
lm_model_univ6 <- glm(phq2_cg_cat ~pa11hlkpfrwrk_recode, data = merged_dementia2_sub)
summary(lm_model_univ6)
lm_model_univ6a <- glm(gad2_cg_cat ~pa11hlkpfrwrk_recode, data = merged_dementia2_sub)
summary(lm_model_univ6a) ##p=0.1
lm_model_univ7 <- glm(phq2_cg_cat ~pa11hlkpfrvol_recode, data = merged_dementia2_sub)
summary(lm_model_univ7)
lm_model_univ7a <- glm(gad2_cg_cat ~pa11hlkpfrvol_recode, data = merged_dementia2_sub)
summary(lm_model_univ7a)
lm_model_univ8 <- glm(phq2_cg_cat ~pa11hlkpfrvol_recode, data = merged_dementia2_sub)
summary(lm_model_univ8) #p=0.1
lm_model_univ7a <- glm(gad2_cg_cat ~pa11hlkpfrvol_recode, data = merged_dementia2_sub)
summary(lm_model_univ7a) #p=0.1
lm_model_univ8a <- glm(gad2_cg_cat ~chd11educ_recode, data = merged_dementia2_sub)
summary(lm_model_univ8a)
lm_model_univ8b <- glm(phq2_cg_cat ~chd11educ_recode, data = merged_dementia2_sub)
summary(lm_model_univ8b)
lm_model_univ9a <- glm(gad2_cg_cat ~c11gender_recode, data = merged_dementia2_sub)
summary(lm_model_univ9a) ##significant
lm_model_univ9b <- glm(phq2_cg_cat ~c11gender_recode, data = merged_dementia2_sub)
summary(lm_model_univ9b) 
lm_model_univ10a <- glm(gad2_cg_cat ~crl11dcgracehisp_recode, data = merged_dementia2_sub)
summary(lm_model_univ10a) 
lm_model_univ10b <- glm(phq2_cg_cat ~crl11dcgracehisp_recode, data = merged_dementia2_sub)
summary(lm_model_univ10b) 
lm_model_univ11a <- lm(gad2_cg_cat ~chi11income, data = merged_dementia2_sub)
summary(lm_model_univ11a) 
lm_model_univ11b <- lm(phq2_cg_cat ~chi11income, data = merged_dementia2_sub)
summary(lm_model_univ11b) # p= 0.1
lm_model_univ12a <- lm(gad2_cg_cat ~chd11dage, data = merged_dementia2_sub)
summary(lm_model_univ11a) 
lm_model_univ12b <- lm(phq2_cg_cat ~chd11dage, data = merged_dementia2_sub)
summary(lm_model_univ12b)  

```

```{r}
#Create subset data from merged_dementia1
merged_dementia2_sub <- subset(
  merged_dementia1,
  select = c(spid, pa11hlkepfvst_recode, pa11hlkpfrclb_recode, pa11hlkpgoenj_recode, pa11hlkpfrwrk_recode, pa11hlkpfrvol_recode, pa11hlkpfrclb_recode, pa11prcranoth_recode, crl11dcgracehisp_recode, total_SS_cat, c11gender_recode, chd11educ_recode, chi11medicaid, chd11dage, gad2_cg_cat, phq2_cg_cat, chi11income, chd11martstat_recode
  ))

#multivariates- indiivdaul caregivers' social strains (depression)
lm_model_multi1 <- glm(phq2_cg_cat~ pa11hlkepfvst_recode + pa11hlkpfrclb_recode + pa11hlkpgoenj_recode + pa11hlkpfrwrk_recode + pa11hlkpfrvol_recode + pa11hlkpfrclb_recode + pa11prcranoth_recode + chd11educ_recode + crl11dcgracehisp_recode + chi11medicaid + chd11dage + chi11income + chd11martstat_recode,  
                       data = merged_dementia2_sub, 
                       family = binomial)
summary (lm_model_multi1)   # income = (p = 0.1)
odds_ratios <- exp(coef(lm_model_multi1))
 odds_ratios
#multivariates (anxiety)
lm_model_multi2 <- glm(gad2_cg_cat~ pa11hlkepfvst_recode + pa11hlkpfrclb_recode + pa11hlkpgoenj_recode + pa11hlkpfrwrk_recode + pa11hlkpfrvol_recode + pa11hlkpfrclb_recode + pa11prcranoth_recode + chd11educ_recode + crl11dcgracehisp_recode + chi11medicaid + chd11dage + chi11income + chd11martstat_recode,  
                       data = merged_dementia2_sub, 
                       family = binomial)
summary (lm_model_multi2) # income (p = 0.1)
odds_ratios <- exp(coef(lm_model_multi2))
 odds_ratios
#multivariates- combined caregivers' social strains and depression
lm_model_multi3 <- glm(phq2_cg_cat ~ total_SS_cat + chd11educ_recode + crl11dcgracehisp_recode + chi11medicaid + chd11dage + chi11income + chd11martstat_recode,
                       data = merged_dementia2_sub, 
                       family = binomial)
summary (lm_model_multi3) # race (p= 0.1)
odds_ratios <- exp(coef(lm_model_multi3))
 odds_ratios

## combined social strains and anxiety 
lm_model_multi4 <- glm(gad2_cg_cat ~ total_SS_cat + chd11educ_recode + crl11dcgracehisp_recode + chi11medicaid + chd11dage + chi11income + chd11martstat_recode,
                       data = merged_dementia2_sub, 
                       family = binomial)
summary (lm_model_multi4) # income (p = 0.1)
odds_ratios <- exp(coef(lm_model_multi4))
 odds_ratios

```

```{r}
# Convert to a data frame (if it's not already) and create training set 'anxiety' and 'depression' 
merged_dementia2_sub <- as.data.frame(merged_dementia2_sub)

anxiety <- merged_dementia2_sub |>
  dplyr::select(total_SS_cat, gad2_cg_cat, chi11income, c11gender_recode, chd11educ_recode, crl11dcgracehisp_recode, chd11dage, chd11martstat_recode) |>
  drop_na()
anxiety

depression <- merged_dementia2_sub |>
  dplyr::select(total_SS_cat, phq2_cg_cat, chi11income, c11gender_recode, chd11educ_recode, crl11dcgracehisp_recode, chd11dage, chd11martstat_recode) |>
  drop_na()
depression
```

Results

*Descriptive studies: The mean age of the caregivers was 62.6 ±13.5 (20–95) years. The majority of participants were female (65.9%), high school graduates (52.3%), married or living with a partner (57.8%), and employed (64.4%). Approximately 72% of the care recipients were identified as having probable dementia, whereas 28% were classified as having possible dementia. Many relied on their caregivers for basic activities of daily living and instrumental activities of daily living. Approximately 26% to 29% of care recipients exhibited behavioral and psychological symptoms, such as anxiety or depression.*

```{r}
library(ggplot2)
library(haven)
summary(merged_dementia1$demclas)
ggplot(merged_dementia1, aes(demclas)) + 
    geom_histogram(breaks = seq(0, 2, 1), 
                   color = "blue", fill = "blue", alpha = 0.7) 
summary(depression)

#Caregiver's age
ggplot(merged_dementia1, aes(chd11dage )) + 
    geom_histogram(aes(y = after_stat(density)), breaks = seq(0, 80, 1), 
                   color = "blue", fill = "blue", alpha = 0.7) +
    geom_density(color = "red")

#Caregiver's gender
ggplot(merged_dementia1, aes(x = factor(c11gender))) + 
  geom_bar(fill = "steelblue", color = "black", alpha = 0.7) +
  scale_x_discrete(
    name = "Gender",
    labels = c("1" = "Male", "2" = "Female")  # Label the genders based on the original codes
  ) +
  labs(
    title = "Gender Distribution", 
    x = "Gender", 
    y = "Count"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "none"  # No legend needed for this plot
  )


#Caregiver's education 
merged_dementia1 <- merged_dementia1 %>%
  filter(!is.na(chd11educ))
ggplot(merged_dementia1, aes(x = chd11educ)) + 
  geom_bar(
    fill = "blue", 
    color = "black", 
    alpha = 0.7
  ) +
  scale_x_discrete(
    name = "Education Level", 
    labels = c(
      "-1" = "No School", 
      "2" = "Primary (1-8th)", 
      "3" = "9-12th Grade", 
      "4" = "High School Diploma", 
      "5" = "Trade Certificate", 
      "6" = "Some College (No Degree)", 
      "7" = "Associate", 
      "8" = "Bachelor's Degree"
    )
  ) +
  labs(
    title = "Distribution of Caregiver Education Levels", 
    x = "Education Level", 
    y = "Count"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for clarity
    legend.position = "none"  # Remove legend (not needed for this plot)
  )

# caregiver's martial status
gplot(merged_dementia1, aes(chd11dage )) + 
    geom_histogram(aes(y = after_stat(density)), breaks = seq(0, 80, 1), 
                   color = "blue", fill = "blue", alpha = 0.7) +
    geom_density(color = "red")
```

# Results

```{r}
#| label: load-packages
#| include: false

library(tidyverse)
library(kernlab)
library(randomForest)
library(glmnet)
library(xgboost)
library(vip)
library(tidymodels)
library(yardstick)
library(pROC)
tidymodels_prefer()
```

Machine learning

```{r}
set.seed(1234)
#Preparing training data 
anxiety <- as.data.frame(anxiety)
anxiet1 <- anxiety |>
  select(total_SS_cat, gad2_cg_cat, chi11income, c11gender_recode, chd11educ_recode, crl11dcgracehisp_recode, chd11dage, chd11martstat_recode) |>
  drop_na() |>
  mutate(ss = factor(total_SS_cat, levels = c(0, 1), 
                           labels = c("false", "true"))) |>
  mutate(anxiety = factor(gad2_cg_cat, levels = c(0, 1),
                         labels = c("false", "true"))) 
anxiet1
anxiety_split <- initial_split(anxiet1, 
                            prop = 0.80)
anxiety_split
anxiety_train <- training(anxiety_split)
anxiety_test <- testing(anxiety_split)
anxiety_train
anxiety_train <- anxiety_train |>
  mutate(anxiety = as.factor(anxiety))
lr_cls_spec <- 
  logistic_reg() |> 
  set_engine("glm")
lr_cls_fit <- 
  lr_cls_spec |>
  fit(anxiety ~ ss, data = anxiety_train)

#Perform 10-fold cross validation on the training data
anxiety_folds <- vfold_cv(anxiety_train, v = 10)
anxiety_folds

#Create a workflow() for fitting the glm
glm_wf <- workflow() |>
  add_model(lr_cls_spec) |>
  add_formula(anxiety ~ ss)
  
#Use workflow to fit model with each fold of resampled data
glm_fit_cv <- 
  glm_wf |>
  fit_resamples(
    resamples = anxiety_folds, 
    control = control_resamples(save_pred = TRUE)
  )

#Collect predictions out of folds into one tibble
anxiety_glm_cv_preds <- collect_predictions(glm_fit_cv)

#Plot of ROC curve of CV results
autoplot(roc_curve(anxiety_glm_cv_preds, 
        anxiety, 
        .pred_true))

#Overall metrics of CV results
collect_metrics(glm_fit_cv) # mean_roc_auc = 0.5652078		
#Prediction on the test data
anxiety.lr.pred.values.test <-  bind_cols(
  truth = anxiet1$anxiety,
  predict(lr_cls_fit, anxiet1),
  predict(lr_cls_fit, anxiet1, type = "prob")
)
anxiety.lr.pred.values.test

#Plot of ROC curve of prediction on test results
autoplot(roc_curve(anxiety.lr.pred.values.test, truth,
                   .pred_true))

#Metrics of prediction on test data
metrics(anxiety.lr.pred.values.test, truth, .pred_class, .pred_true)
#roc_auc = 0.4495781		
#accuracy = 0.6968085	
```

The evaluation of the binary classification model shows that its performance is below expectations across several key metrics. With an accuracy of 69.7%, the model correctly predicted the outcome in nearly 70% of cases. However, accuracy alone does not provide a complete picture of model performance, especially in imbalanced datasets, where a higher accuracy may simply result from predicting the majority class.

The Kappa statistic of 0.0 indicates that there is no better agreement between the predicted and actual labels than what would be expected from random guessing. This implies that the model's predictions lack meaningful predictive power. Furthermore, the mean logarithmic loss of 0.95 highlights the model's deficiencies in generating reliable probabilistic predictions. A higher log loss penalizes incorrect predictions more severely, particularly when the model is overly confident in its mistakes. This suggests that the model’s probability estimates are not well-calibrated.

Additionally, the ROC AUC score of 0.45, which is only slightly above random guessing (0.5), reflects the model’s limited ability to differentiate between classes.

Overall, these results indicate that the model’s predictive capabilities are inadequate and that improvements are necessary. Potential enhancements may include addressing class imbalance, refining feature engineering, optimizing hyperparameters, or exploring more advanced models to improve classification performance and accuracy in probabilistic predictions.

```{r}
depress1 <- depression |>
  select(total_SS_cat, phq2_cg_cat, chi11income, c11gender_recode, chd11educ_recode, crl11dcgracehisp_recode, chd11dage, chd11martstat_recode) |>
  drop_na() |>
  mutate(ss = factor(total_SS_cat, levels = c(0, 1), 
                           labels = c("false", "true"))) |>
  mutate(depression = factor(phq2_cg_cat, levels = c(0, 1),
                         labels = c("false", "true"))) 
depress1

depression_split <- initial_split(depress1, 
                            prop = 0.80)
depression_split

depression_train <- training(depression_split)
depression_test <- testing(depression_split)

depression_train

depression_train <- depression_train |>
  mutate(depression = as.factor(depression))

lr_cls_spec <- 
  logistic_reg() |> 
  set_engine("glm")

lr_cls_fit <- 
  lr_cls_spec |>
  fit(depression ~ ss, data = depression_train)

#Perform 10-fold cross validation on the training data
depression_folds <- vfold_cv(depression_train, v = 10)
anxiety_folds

#Create a workflow() for fitting the glm
glm_wf <- workflow() |>
  add_model(lr_cls_spec) |>
  add_formula(depression ~ ss)
  
#Use workflow to fit model with each fold of resampled data
glm_fit_cv <- 
  glm_wf |>
  fit_resamples(
    resamples = depression_folds, 
    control = control_resamples(save_pred = TRUE)
  )

#Collect predictions out of folds into one tibble
depression_glm_cv_preds <- collect_predictions(glm_fit_cv)

#Plot of ROC curve of CV results
autoplot(roc_curve(depression_glm_cv_preds, 
        depression, 
        .pred_true))

#Overall metrics of CV results
collect_metrics(glm_fit_cv) # mean_roc_auc = 0.4892388			
#Prediction on the test data
depression.lr.pred.values.test <-  bind_cols(
  truth = depress1$depression,
  predict(lr_cls_fit, depress1),
  predict(lr_cls_fit, depress1, type = "prob")
)
depression.lr.pred.values.test

#Plot of ROC curve of prediction on test results
autoplot(roc_curve(depression.lr.pred.values.test, truth, .pred_true))

#Metrics of prediction on test data
metrics(anxiety.lr.pred.values.test, truth, .pred_class, .pred_true) #ROC_AUC 0.4495781, accuracy 0.6968085	
```

```{r}
#SVM- Train the SVM Model. 
#anxiety ~ ss: Specifies that anxiety is the target variable and ss is the predictor variable.

#Model specification
svm_spec <- 
  svm_linear(cost = 1) |> 
  set_engine("kernlab") |>
  set_mode("classification") 
svm_spec

#Fit on the training data
svm_cls_fit <- svm_spec |>
  fit(anxiety ~ ss, data = anxiet1)
svm_cls_fit

anxiety.svm.pred.values <- bind_cols(
  truth = anxiet1$anxiety,  
  class_pred = predict(svm_cls_fit, anxiet1),  # Predicted class labels
  prob_pred = predict(svm_cls_fit, anxiet1, type = "prob")  # Predicted probabilities
)

roc_auc(anxiety.svm.pred.values, 
        truth, 
        .pred_true)
anxiety.svm.pred.values <- bind_cols(
  truth = anxiet1$anxiety,
  predict(svm_cls_fit, anxiet1, type = "prob")
)
roc_auc(anxiety.svm.pred.values, 
        truth, 
        .pred_true)
autoplot(roc_curve(anxiety.svm.pred.values, 
                   truth, 
                   .pred_true))
#Fit on the training data
svm_cls_fit <- svm_spec |>
  fit(anxiety ~ ss, data = anxiet1)
svm_cls_fit

# Bind the true labels, predicted class, and predicted probabilities
anxiety.svm.pred.values <- bind_cols(
  truth = anxiet1$anxiety,  # Actual labels (outcome)
  class_pred = predict(svm_cls_fit, anxiet1),  # Predicted class labels (using anxiet1)
  prob_pred = predict(svm_cls_fit, anxiet1, type = "prob")  # Predicted probabilities
)
# View the resulting predictions
View(anxiety.svm.pred.values)
roc_auc(anxiety.svm.pred.values, 
        truth, 
        .pred_true)
anxiety.svm.pred.values <- bind_cols(
  truth = anxiet1$anxiety,  # Actual outcomes
  predict(svm_cls_fit, anxiet1, type = "prob")  # Predicted probabilities
)
roc_auc(
  anxiety.svm.pred.values, 
  truth = truth, 
  .pred_true  
)
autoplot(roc_curve(anxiety.svm.pred.values, 
                   truth, 
                   .pred_true))
```

The evaluation of the Support Vector Machine (SVM) model indicates that it is not performing well for the given classification task. The model employs a linear kernel with a cost parameter (C = 1), which is typically used to balance the trade-off between minimizing training error and maintaining a simple, generalizable model. However, the results show limited effectiveness. The training error rate of 30.3% means that approximately one-third of the training samples were misclassified, which is relatively high and reflects poor performance. Additionally, the objective function value of -114 does not indicate an optimal fit for the data. The use of 114 support vectors suggests that the model is relying on a relatively small subset of the training data to define the decision boundary, raising concerns of overfitting or inadequate model specification. The most alarming metric is the ROC AUC score of 0.5, which corresponds to random guessing. An ROC AUC of 0.5 indicates that the model has no distinguishing power between the classes, making predictions no better than chance. This suggests that the linear SVM model is unsuitable for this specific dataset, and further refinement, feature selection, or consideration of alternative algorithms may be necessary to enhance performance.

```{r}
svm_workflow <-
  workflow() |>
  add_model(svm_spec) |>
  add_formula(anxiety ~ ss)

svm_fit_cv <-
  svm_workflow |>
  fit_resamples(anxiety_folds, 
                control = control_resamples(save_pred = TRUE))

collect_metrics(svm_fit_cv) #roc_auc 0.5000000

svm_fit_cv |>
  collect_predictions() |>
  roc_curve(anxiety, .pred_true) |>
  autoplot()
```

#Random forest

```{r}
rf_spec <- 
  rand_forest(trees = 1000, min_n = 5) |> 
  set_engine("randomForest", importance = TRUE) |>
  set_mode("classification")
rf_spec
# Train a random forest model
rf_model <- randomForest(anxiety ~  ss, 
                         data=anxiet1, ntree=100)
# Make predictions -> highet F1 score-> we can say that for decision tool,
#random forest model is the best model in this dataset; among the 4 different algorithms tested previously

rf_pred <- predict(rf_model, newdata=anxiet1)
conf_matrix_rf <-confusionMatrix(rf_pred, anxiet1$ss)
precision_rf <- conf_matrix_rf$byClass["Pos Pred Value"]  # Precision
recall_rf <- conf_matrix_rf$byClass["Sensitivity"]        # Recall
f1_score_rf <- 2 * (precision_rf * recall_rf) / (precision_rf + recall_rf)
cat("F1-score_svm:", f1_score_rf)  # F1-score = 0.9037901
#### Set up the trainControl for 5-fold cross-validation
train_control <- trainControl(method = "cv", number = 5)
# Step 1: Predict probabilities
rf_probs <- predict(rf_model, newdata = anxiet1, type = "prob")

# Compute ROC Curve
# Assuming anxiet1$ss is the true label and rf_probs[, "positive_class"] gives probabilities for the positive class
roc_obj <- roc(anxiet1$ss, rf_probs[, "true"])  
# AUC
auc_value <- auc(roc_obj)
cat("AUC:", auc_value, "\n")

#Plot ROC Curve
ggroc(roc_obj) +
  ggtitle("ROC Curve for Random Forest Model") +
  xlab("False Positive Rate") +
  ylab("True Positive Rate")
anxiet1$ss <- factor(anxiet1$ss, levels = levels(anxiet1$ss))

rf_fit <- rf_spec |>
  fit(anxiety ~ ss, data = anxiet1)
rf_fit


anxiety.rf.pred.values <- bind_cols(
  truth = anxiet1$anxiety,  # Actual outcome variable
  class_pred = predict(rf_fit, anxiet1),  # Predicted class labels using the correct dataset
  prob_pred = predict(rf_fit, anxiet1, type = "prob")  # Predicted probabilities
)

# View the resulting predictions
anxiety.rf.pred.values
roc_auc(anxiety.rf.pred.values,
        truth, 
        .pred_false)
autoplot(roc_curve(anxiety.rf.pred.values, 
                   truth, 
                   .pred_true))
### use SS


rf_fit <- rf_spec |>
  fit(anxiety ~ ss, data = anxiet1)
rf_fit

anxiety.rf.pred.values <- bind_cols(
  truth = anxiet1$anxiety,
  predict(rf_fit, anxiet1),
  predict(rf_fit, anxiet1, type = "prob")
)

roc_auc(anxiety.rf.pred.values,
        truth, 
        .pred_true)

autoplot(roc_curve(anxiety.rf.pred.values, 
                   truth, 
                   .pred_true))
metrics(anxiety.rf.pred.values, truth, .pred_class, .pred_true) #roc_auc = 0.5504219	
```

#cross-validation
```{r}
# Set up 5-fold cross-validation
train_control <- trainControl(method = "cv", number = 5)

# Train Random Forest model with cross-validation
rf_model_cv <- train(
  depression ~ ss,         # Formula
  data = depress1,          # Data
  method = "rf",            # Random Forest method
  trControl = train_control,  # Cross-validation settings
  ntree = 100,              # Number of trees
  tuneLength = 3            # Tuning parameter length for mtry
)

# Print the results of cross-validation
print(rf_model_cv)

# Get the final model (after cross-validation)
final_rf_model <- rf_model_cv$finalModel
depress1$ss <- as.factor(depress1$ss)

rf_pred <- predict(final_rf_model, newdata = depress1)

# View the predictions
head(rf_pred)

# Check confusion matrix for evaluation
conf_matrix <- confusionMatrix(rf_pred, depress1$depression)
print(conf_matrix)

# Evaluate other metrics (e.g., F1-score, AUC)
precision_rf <- conf_matrix$byClass["Pos Pred Value"]
recall_rf <- conf_matrix$byClass["Sensitivity"]
f1_score_rf <- 2 * (precision_rf * recall_rf) / (precision_rf + recall_rf)
cat("F1-score:", f1_score_rf)

```


```{r}
library(caret)
#depression
rf_spec <- 
  rand_forest(trees = 1000, min_n = 5) |> 
  set_engine("randomForest", importance = TRUE) |>
  set_mode("classification")

# Train a random forest model for depression
rf_model <- randomForest(depression ~ ss, 
                         data = depress1, ntree = 100)

# Make predictions
rf_pred <- predict(rf_model, newdata = depress1)
conf_matrix_rf <- confusionMatrix(rf_pred, depress1$ss)

# Extract Precision, Recall, and F1 Score
precision_rf <- conf_matrix_rf$byClass["Pos Pred Value"]  # Precision
recall_rf <- conf_matrix_rf$byClass["Sensitivity"]        # Recall
f1_score_rf <- 2 * (precision_rf * recall_rf) / (precision_rf + recall_rf)
cat("F1-score_rf:", f1_score_rf, "\n")  # Print F1 score #F1-score_rf: 0.9037901 

# Predict probabilities
rf_probs <- predict(rf_model, newdata = depress1, type = "prob")

# Compute ROC Curve
roc_obj <- roc(depress1$ss, rf_probs[, "true"])  
auc_value <- auc(roc_obj)
cat("AUC:", auc_value, "\n")  # Print AUC = AUC: 1 

# Plot ROC Curve
ggroc(roc_obj) +
  ggtitle("ROC Curve for Random Forest Model (Depression)") +
  xlab("False Positive Rate") +
  ylab("True Positive Rate")

# Prepare the dataset for prediction and evaluation
depression.rf.pred.values <- bind_cols(
  truth = depress1$depression,  # Actual outcome variable (true labels)
  .pred_class = depress1$ss,  # Predicted class labels
  .pred_true = ss[, "true"],  # Predicted probability for the 'true' class
  .pred_false = ss[, "false"]  # Predicted probability for the 'false' class
)

# Print the resulting data frame to check the columns
print(depression.rf.pred.values)

# Now calculate the metrics
metrics_result <- metrics(depression.rf.pred.values, truth, .pred_class, .pred_true)

# Print the result of the metrics calculation
print(metrics_result)
```

```{r}
XGBoost
# Model specification
bt_spec <- 
  boost_tree(trees = 50,
             tree_depth = 4) |>
  set_mode("classification") |>
  set_engine("xgboost")

# Recipe
bt_recipe <-
  recipe(ss ~ ., data = anxiet1) |>
  step_dummy(all_nominal_predictors()) |>
  step_normalize(all_predictors())

# Workflow specification
bt_workflow <- workflow() |>
  add_model(bt_spec) |>
  add_recipe(bt_recipe)

# Model fit to the training data
bt_fit <- fit(bt_workflow, data = anxiet1)

# Predictions (bind truth and predictions)
anxiet1.bt.pred.values <- bind_cols(
  truth = anxiet1$ss,
  predict(bt_fit, anxiet1),
  predict(bt_fit, anxiet1, type = "prob")
)

# Evaluate model performance (ROC AUC)
roc_auc(anxiet1.bt.pred.values, truth, .pred_true)

# Plot ROC curve
autoplot(roc_curve(anxiet1.bt.pred.values, truth, .pred_true))

# Variable importance using vip
vip(bt_fit)

# Variable importance extracted from the xgboost model object
bt_object <- pull_workflow_fit(bt_fit)$fit
xgb.importance(model = bt_object)




```

XGbooster: The analysis shows that `total_SS_cat` is the most important variable, overwhelmingly driving the model's predictive accuracy with the highest gain (99.9%), cover (90.5%), and frequency (57.7%). Secondary variables like `chd11dage` (age) and `chi11income` (income) have moderate importance, contributing to 5% and 2.3% of splits, respectively. In contrast, `c11gender_recode` (gender) and `chd11martstat_recode` (marital status) have minimal impact, with low gain, cover, and frequency (3.8% each), suggesting they may not significantly enhance the model. Future iterations should focus on the dominant role of `total_SS_cat` while reconsidering less impactful variables to streamline the model.

# Conclusion

@Conclusion

*This the conclusion. The @sec-results can be invoked here.*
